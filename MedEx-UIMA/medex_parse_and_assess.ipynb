{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert MedEx output to i2b2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_no_drools = os.listdir(\"./output_no_drools/\") #folder containing medex-processed test files (drools rule engine was not used)\n",
    "output_with_drools = os.listdir(\"./output_with_drools/\") #folder containing medex-processed test files (drools rule engine was used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./output_no_drools_i2b2/\")\n",
    "os.makedirs(\"./output_with_drools_i2b2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy \"train.test.released.8.17.09\" folder from i2b2 to this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output without drools rule engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in output_no_drools:\n",
    "        \n",
    "    lst = [] # [line index, line] for line in file\n",
    "    first_char_to_line_token = {} # {first character index: (line index, token index),...}\n",
    "    last_char_to_line_token = {} # {last character index: (line index, token index),...}\n",
    "    t_len = 0  # counts characters per token\n",
    "\n",
    "    with open(\"./output_no_drools/\"+file) as r:\n",
    "\n",
    "        x = r.readlines()\n",
    "        e = enumerate(x)\n",
    "        for line_id, line in e:\n",
    "            lst.append([line_id, line])\n",
    "\n",
    "    with open(\"./train.test.released.8.17.09/\"+file) as inputfile:\n",
    "\n",
    "        input_txt = inputfile.read().lower()\n",
    "        input_lines = input_txt.split(\"\\n\")\n",
    "        for l_id, l in enumerate(input_lines):  \n",
    "            for t_id, t in enumerate(l.split()):  \n",
    "                first_char_id = input_txt.find(t, t_len)\n",
    "                last_char_id = first_char_id + len(t)\n",
    "                first_char_to_line_token[first_char_id] = (l_id+1, t_id)\n",
    "                last_char_to_line_token[last_char_id] = (l_id+1, t_id)\n",
    "                t_len = first_char_id + len(t)\n",
    "\n",
    "    with open(\"./output_no_drools_i2b2/\"+file, \"w\") as w:\n",
    "        for line_id, line in lst:\n",
    "            if \"|\" not in line.split()[0]: # only loop over lines that contain medication mentions\n",
    "\n",
    "                line = line.replace(\"\\t\", \"|\", 1)\n",
    "                line = line.split(\"|\")\n",
    "\n",
    "                m = line[2].split(\"[\")[0] #presumed that there is no \"[\" in the medication name\n",
    "                first_char_id = int(line[2].split(\"[\")[-1].split(\",\")[0])  \n",
    "                last_char_id = int(line[2].split(\"[\")[-1].split(\",\")[-1][:-1])\n",
    "                idx = int(line[0])\n",
    "\n",
    "                # medex treats tokens in the form of XXX-XXX, XXX/XXX, and XXX+XXX as two tokens \n",
    "                # which leads to inaccurate start/end indices\n",
    "                while True: \n",
    "                    try:\n",
    "                        first_m_line_id = first_char_to_line_token[int(first_char_id)][0]\n",
    "                        first_m_token_id = first_char_to_line_token[int(first_char_id)][1]\n",
    "                        break\n",
    "                    except:\n",
    "                        first_char_id -= 1\n",
    "\n",
    "                while True:\n",
    "                    try: \n",
    "                        last_m_line_id = last_char_to_line_token[int(last_char_id)][0]\n",
    "                        last_m_token_id = last_char_to_line_token[int(last_char_id)][1]\n",
    "                        break\n",
    "                    except:\n",
    "                        last_char_id += 1\n",
    "\n",
    "                annotation = f'm=\"{m}\" {first_m_line_id}:{first_m_token_id} {last_m_line_id}:{last_m_token_id}||du=\"nm\"\\n' \n",
    "                # dummy annotation\n",
    "\n",
    "                for sent_id, sent in lst:\n",
    "\n",
    "                    if '|' in sent.split()[0] and 'DRT' in sent and int(sent.split('|')[0]) == idx-1: \n",
    "                        # only duration mentions related to drugs are relevant!\n",
    "\n",
    "                        dur = sent.split('|')[-4]\n",
    "                        first_du_char_id = int(sent.split('|')[-2])\n",
    "                        last_du_char_id = int(sent.split('|')[-1])\n",
    "\n",
    "                        if dur in line[1]:\n",
    "\n",
    "                            first_du_line_id = first_char_to_line_token[int(first_du_char_id)][0]\n",
    "                            first_du_token_id = first_char_to_line_token[int(first_du_char_id)][1]\n",
    "\n",
    "                            last_du_line_id = last_char_to_line_token[int(last_du_char_id)][0]\n",
    "                            last_du_token_id = last_char_to_line_token[int(last_du_char_id)][1]\n",
    "\n",
    "                            annotation = f'm=\"{m}\" {first_m_line_id}:{first_m_token_id} {last_m_line_id}:{last_m_token_id}||du=\"{dur}\" {first_du_line_id}:{first_du_token_id} {last_du_line_id}:{last_du_token_id}\\n'\n",
    "\n",
    "                w.write(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output with Drools rule engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in output_with_drools:\n",
    "    \n",
    "    lst = [] # all lines in file\n",
    "    first_char_to_line_token = {} # {first character index: (line index, token index),...}\n",
    "    last_char_to_line_token = {} # {last character index: (line index, token index),...}\n",
    "    t_len = 0  # counts characters per token\n",
    "    \n",
    "    with open(\"./output_with_drools/\"+file) as r:\n",
    "        \n",
    "        x = r.readlines()\n",
    "        e = enumerate(x)\n",
    "        for line_id, line in e:\n",
    "            lst.append([line_id, line])\n",
    "    \n",
    "    with open(\"./train.test.released.8.17.09/\"+file) as inputfile:\n",
    "        \n",
    "        input_txt = inputfile.read().lower()\n",
    "        input_lines = input_txt.split(\"\\n\")\n",
    "        for l_id, l in enumerate(input_lines):  \n",
    "            for t_id, t in enumerate(l.split()):  \n",
    "                first_char_id = input_txt.find(t, t_len)\n",
    "                last_char_id = first_char_id + len(t)\n",
    "                first_char_to_line_token[first_char_id] = (l_id+1, t_id)\n",
    "                last_char_to_line_token[last_char_id] = (l_id+1, t_id)\n",
    "                t_len = first_char_id + len(t)\n",
    "                    \n",
    "    with open(\"./output_with_drools_i2b2/\"+file, \"w\") as w:\n",
    "        for line_id, line in lst:\n",
    "            if \"|\" not in line.split()[0]: # only loop over lines that contain medication mentions\n",
    "                \n",
    "                line = line.replace(\"\\t\", \"|\", 1)\n",
    "                line = line.split(\"|\")\n",
    "                \n",
    "                m = line[2].split(\"[\")[0] #presumed that there is no \"[\" in the medication name\n",
    "                first_char_id = int(line[2].split(\"[\")[-1].split(\",\")[0])  \n",
    "                last_char_id = int(line[2].split(\"[\")[-1].split(\",\")[-1][:-1])\n",
    "                idx = int(line[0])\n",
    "\n",
    "                # medex treats tokens in the form of XXX-XXX, XXX/XXX, and XXX+XXX as two tokens \n",
    "                # which leads to inaccurate start/end indices\n",
    "                while True: \n",
    "                    try:\n",
    "                        first_m_line_id = first_char_to_line_token[int(first_char_id)][0]\n",
    "                        first_m_token_id = first_char_to_line_token[int(first_char_id)][1]\n",
    "                        break\n",
    "                    except:\n",
    "                        first_char_id -= 1\n",
    "\n",
    "                while True:\n",
    "                    try: \n",
    "                        last_m_line_id = last_char_to_line_token[int(last_char_id)][0]\n",
    "                        last_m_token_id = last_char_to_line_token[int(last_char_id)][1]\n",
    "                        break\n",
    "                    except:\n",
    "                        last_char_id += 1\n",
    "\n",
    "                annotation = f'm=\"{m}\" {first_m_line_id}:{first_m_token_id} {last_m_line_id}:{last_m_token_id}||du=\"nm\"\\n' \n",
    "                # dummy annotation\n",
    "\n",
    "                for sent_id, sent in lst:\n",
    "\n",
    "                    if '|' in sent.split()[0] and 'DRT' in sent and int(sent.split('|')[0]) == idx-1: \n",
    "                        # only duration mentions related to drugs are relevant!\n",
    "\n",
    "                        dur = sent.split('|')[-4]\n",
    "                        first_du_char_id = int(sent.split('|')[-2])\n",
    "                        last_du_char_id = int(sent.split('|')[-1])\n",
    "\n",
    "                        if dur in line[1]:\n",
    "                            \n",
    "                            first_du_line_id = first_char_to_line_token[int(first_du_char_id)][0]\n",
    "                            first_du_token_id = first_char_to_line_token[int(first_du_char_id)][1]\n",
    "\n",
    "                            while True:\n",
    "                                try:\n",
    "                                    last_du_line_id = last_char_to_line_token[int(last_du_char_id)][0]\n",
    "                                    last_du_token_id = last_char_to_line_token[int(last_du_char_id)][1]\n",
    "                                    break\n",
    "                                except:\n",
    "                                    last_du_char_id += 1\n",
    "                                    \n",
    "                            annotation = f'm=\"{m}\" {first_m_line_id}:{first_m_token_id} {last_m_line_id}:{last_m_token_id}||du=\"{dur}\" {first_du_line_id}:{first_du_token_id} {last_du_line_id}:{last_du_token_id}\\n'\n",
    "\n",
    "                w.write(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MedEx-UIMA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./human_annotations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all files in the i2b2 folders \"annotations_ground_truth/converted.noduplicates.sorted/\" (except 'bucharest_v1.py' and '827931.Alan.Aronson.NIH.NLM.a1_827931.Faisal.Farooq.Siemens.a2.Kim.m.save') and in \"training_ground_truth\" (except 'CHANGE.HISTORY.txt') to the \"human_annotations\" folder created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = os.listdir('./human_annotations/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in annotations:\n",
    "    try:\n",
    "        base = re.split(r'\\D', filename)[0]\n",
    "        os.rename('./human_annotations/'+filename, './human_annotations/'+base)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually rename any files that were skipped: Only the file indices should be kept, e.g. '1234_gold' => '1234'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token matches, no Drools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug precision: 0.9317\n",
      "Drug recall: 0.8112\n",
      "Drug F1: 0.8673\n",
      "\n",
      "Duration precision: 0.5714\n",
      "Duration recall: 0.129\n",
      "Duration F1: 0.2105\n",
      "\n",
      "Micro precision: 0.9239\n",
      "Micro recall: 0.7579\n",
      "Micro F1: 0.8327\n"
     ]
    }
   ],
   "source": [
    "m_tp = 0\n",
    "m_fn = 0\n",
    "m_fp = 0\n",
    "\n",
    "dur_tp = 0\n",
    "dur_fn = 0\n",
    "dur_fp = 0\n",
    "\n",
    "for filename in output_no_drools:\n",
    "    \n",
    "    pred_dict = {} # predicted medication index: related predicted duration index\n",
    "    gold_dict = {} # gold medication index: related gold duration index\n",
    "    \n",
    "    with open(\"./output_no_drools_i2b2/\"+filename) as m, open(\"./human_annotations/\"+filename) as h:\n",
    "        \n",
    "        machine_lines = m.readlines()\n",
    "        human_lines = h.readlines()\n",
    "        \n",
    "    for line in machine_lines:\n",
    "            \n",
    "        m = line.split('||')[0]\n",
    "        dur = line.split('||')[1]\n",
    "        m_idx = ' '.join(m.split()[-2:])\n",
    "            \n",
    "        if dur.lower().strip() == 'du=\"nm\"':\n",
    "            pred_dict[m_idx] = 'du=\"nm\"' \n",
    "        else:\n",
    "            dur_idx = ' '.join(dur.split()[-2:])\n",
    "            pred_dict[m_idx] = dur_idx\n",
    "                    \n",
    "    for line in human_lines:\n",
    "            \n",
    "        m = line.split('||')[0]\n",
    "        dur = line.split('||')[1]\n",
    "        m_idx = ' '.join(m.split()[-2:])\n",
    "            \n",
    "        if dur.lower().split() == 'du=\"nm\"':\n",
    "            gold_dict[m_idx] = 'du=\"nm\"'\n",
    "            \n",
    "        else:\n",
    "            dur_idx = ' '.join(dur.split()[-2:])\n",
    "            gold_dict[m_idx] = dur_idx\n",
    "                                \n",
    "    for drug, duration in pred_dict.items(): \n",
    "        pred_drug_line = int(drug.split(':')[0])\n",
    "        pred_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "        pred_drug_end_token = int(drug.split(':')[-1])\n",
    "        pred_drug = range(pred_drug_start_token, pred_drug_end_token+1)\n",
    "        drug_cnt = 0 # turns to 1 if a corresponding drug was found in the human annotations\n",
    "            \n",
    "        for drug in gold_dict.keys():\n",
    "            gold_drug_line = int(drug.split(':')[0])\n",
    "            try:\n",
    "                gold_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "            except: # one exception found were drug = \"217:1,217:3 217:3\" instead of \"217:1 217:3\"\n",
    "                gold_drug_start_token = int(drug.split(':')[1].split(',')[0])       \n",
    "            gold_drug_end_token = int(drug.split(':')[-1])\n",
    "            gold_drug = range(gold_drug_start_token, gold_drug_end_token+1)\n",
    "            overlap = set(pred_drug) & set(gold_drug)\n",
    "                \n",
    "            if pred_drug_line == gold_drug_line and overlap: \n",
    "                # corresponding drug mention found, assuming that drug mentions are not split over lines\n",
    "                \n",
    "                drug_cnt += 1\n",
    "                m_tp += len(overlap)\n",
    "                \n",
    "                if pred_drug_end_token > gold_drug_end_token:\n",
    "                    m_fp += pred_drug_end_token - gold_drug_end_token\n",
    "                if pred_drug_end_token < gold_drug_end_token:\n",
    "                    m_fn += gold_drug_end_token - pred_drug_end_token\n",
    "                if pred_drug_start_token < gold_drug_start_token:\n",
    "                    m_fp += gold_drug_start_token - pred_drug_start_token\n",
    "                if pred_drug_start_token > gold_drug_start_token:\n",
    "                    m_fn += pred_drug_start_token - gold_drug_start_token\n",
    "                    \n",
    "                break\n",
    "                    \n",
    "        if drug_cnt == 0:\n",
    "            m_fp += pred_drug_end_token - pred_drug_start_token + 1\n",
    "                \n",
    "        if duration.strip() != 'du=\"nm\"':\n",
    "            pred_start_line = int(duration.split(':')[0])\n",
    "            pred_end_line = int(duration.split(':')[1].split()[-1])\n",
    "            pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "            pred_dur_end_token = int(duration.split(':')[-1])\n",
    "            dur_cnt = 0 # turns to 1 if a corresponding duration was found in the human annotations\n",
    "            \n",
    "            if pred_start_line == pred_end_line:\n",
    "                pred_dur = range(pred_dur_start_token, pred_dur_end_token+1)\n",
    "                \n",
    "                for duration in gold_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        gold_dur_line = int(duration.split(':')[0])\n",
    "                        gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        gold_dur_end_token = int(duration.split(':')[-1])\n",
    "                        gold_dur = range(gold_dur_start_token, gold_dur_end_token+1)\n",
    "                        overlap = set(pred_dur) & set(gold_dur)\n",
    "                \n",
    "                        if pred_start_line == gold_dur_line and overlap:\n",
    "                            dur_cnt += 1\n",
    "                            dur_tp += len(overlap)\n",
    "                            \n",
    "                            if pred_dur_end_token > gold_dur_end_token:\n",
    "                                dur_fp += pred_dur_end_token - gold_dur_end_token\n",
    "                            if pred_dur_end_token < gold_dur_end_token:\n",
    "                                dur_fn += gold_dur_end_token - pred_dur_end_token\n",
    "                            if pred_dur_start_token < gold_dur_start_token:\n",
    "                                dur_fp += gold_dur_start_token - pred_dur_start_token\n",
    "                            if pred_dur_start_token > gold_dur_start_token:\n",
    "                                dur_fn += pred_dur_start_token - gold_dur_start_token\n",
    "                            break\n",
    "                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fp += pred_dur_end_token - pred_dur_start_token + 1\n",
    "                            \n",
    "            else:  \n",
    "                with open('./input/'+filename) as f:\n",
    "                    x = f.readlines()\n",
    "                    for idx, line in enumerate(x):\n",
    "                        if idx+1 == int(pred_start_line):\n",
    "                            line_len = len(line.split())\n",
    "                            break\n",
    "                            \n",
    "                for duration in gold_dict.values():\n",
    "                     if duration.strip() != 'du=\"nm\"':\n",
    "                        gold_start_line = int(duration.split(':')[0])\n",
    "                        gold_end_line = int(duration.split(':')[1].split()[-1])\n",
    "                        gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        gold_dur_end_token = int(duration.split(':')[-1])\n",
    "                                    \n",
    "                        if pred_start_line == gold_start_line and pred_end_line == gold_end_line:\n",
    "                            first_line_overlap = set(range(pred_dur_start_token, line_len)) & set(range(gold_dur_start_token, line_len))\n",
    "                            second_line_overlap = set(range(0, pred_dur_end_token+1)) & set(range(0, gold_dur_end_token+1))\n",
    "                            \n",
    "                            if first_line_overlap or second_line_overlap:\n",
    "                                dur_cnt += 1\n",
    "                                dur_tp += len(first_line_overlap)+len(second_line_overlap)\n",
    "                                \n",
    "                                if pred_dur_end_token > gold_dur_end_token:\n",
    "                                    dur_fp += pred_dur_end_token - gold_dur_end_token\n",
    "                                if pred_dur_end_token < gold_dur_end_token:\n",
    "                                    dur_fn += gold_dur_end_token - pred_dur_end_token\n",
    "                                if pred_dur_start_token < gold_dur_start_token:\n",
    "                                    dur_fp += gold_dur_start_token - pred_dur_start_token\n",
    "                                if pred_dur_start_token > gold_dur_start_token:\n",
    "                                    dur_fn += pred_dur_start_token - gold_dur_start_token\n",
    "                                break \n",
    "                        \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fp += (line_len - pred_dur_start_token) + (0 + pred_dur_end_token)\n",
    "                \n",
    "    for drug, duration in gold_dict.items():\n",
    "        \n",
    "        gold_drug_line = int(drug.split(':')[0])\n",
    "        try:\n",
    "            gold_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "        except:\n",
    "            gold_drug_start_token = int(drug.split(':')[1].split(',')[0])\n",
    "        gold_drug_end_token = int(drug.split(':')[-1])\n",
    "        gold_drug = range(gold_drug_start_token, gold_drug_end_token+1)\n",
    "        gold_cnt = 0\n",
    "            \n",
    "        for drug in pred_dict.keys():\n",
    "            \n",
    "            pred_drug_line = int(drug.split(':')[0])\n",
    "            pred_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "            pred_drug_end_token = int(drug.split(':')[-1])\n",
    "            pred_drug = range(pred_drug_start_token, pred_drug_end_token+1)\n",
    "            overlap = set(pred_drug) & set(gold_drug)\n",
    "                \n",
    "            if pred_drug_line == gold_drug_line and overlap:\n",
    "                drug_cnt += 1\n",
    "                break\n",
    "                \n",
    "        if drug_cnt == 0:\n",
    "            m_fn += len(gold_drug)\n",
    "            \n",
    "        if duration != 'du=\"nm\"':\n",
    "            gold_dur_start_line = int(duration.split(':')[0])\n",
    "            gold_dur_end_line = int(duration.split(':')[1].split()[-1])\n",
    "            gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "            gold_dur_end_token = int(duration.split(':')[-1])\n",
    "            dur_cnt = 0\n",
    "            \n",
    "            if gold_dur_start_line == gold_dur_end_line:\n",
    "                gold_dur = range(gold_dur_start_token, gold_dur_end_token)\n",
    "                for duration in pred_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        pred_dur_line = int(duration.split(':')[0])\n",
    "                        pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        pred_dur_end_token = int(duration.split(':')[-1])\n",
    "                        pred_dur = range(pred_dur_start_token, pred_dur_end_token)\n",
    "                        overlap = set(pred_dur) & set(gold_dur)\n",
    "                \n",
    "                        if pred_dur_line == gold_dur_start_line and overlap:\n",
    "                            dur_cnt += 1\n",
    "                            break\n",
    "                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fn += len(gold_dur) \n",
    "                    \n",
    "            else:\n",
    "                for duration in pred_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        pred_dur_start_line = int(duration.split(':')[0])\n",
    "                        pred_dur_end_line = int(duration.split(':')[1].split()[-1])\n",
    "                        pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        pred_dur_end_token = int(duration.split(':')[-1])\n",
    "                        \n",
    "                        with open('./input/'+filename) as f:\n",
    "                            x = f.readlines()\n",
    "                            for idx, line in enumerate(x):\n",
    "                                if idx+1 == int(pred_start_line):\n",
    "                                    line_len = len(line.split())\n",
    "                                    break\n",
    "                                    \n",
    "                        if pred_dur_start_line == gold_dur_start_line and pred_dur_end_line == gold_dur_end_line:\n",
    "                            first_line_overlap = set(range(pred_dur_start_token, line_len)) & set(range(gold_dur_start_token, line_len))\n",
    "                            last_line_overlap = set(range(0, pred_dur_end_token+1)) & set(range(0, gold_dur_end_token+1))\n",
    "                            \n",
    "                            if first_line_overlap or second_line_overlap:\n",
    "                                dur_cnt += 1\n",
    "                                break\n",
    "                                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fn += len(gold_dur)\n",
    "                                                                         \n",
    "m_precision = m_tp / (m_tp + m_fp)\n",
    "m_recall = m_tp / (m_tp + m_fn)\n",
    "m_f1 = 2 * (m_precision * m_recall) / (m_precision + m_recall)\n",
    "\n",
    "print(\"Drug precision: \" + str(round(m_precision, 4)))\n",
    "print(\"Drug recall: \" + str(round(m_recall, 4)))\n",
    "print(\"Drug F1: \" + str(round(m_f1, 4)) + \"\\n\")\n",
    "\n",
    "dur_precision = dur_tp / (dur_tp + dur_fp)\n",
    "dur_recall = dur_tp / (dur_tp + dur_fn)\n",
    "dur_f1 = 2 * (dur_precision * dur_recall) / (dur_precision + dur_recall)\n",
    "\n",
    "print(\"Duration precision: \" + str(round(dur_precision, 4)))\n",
    "print(\"Duration recall: \" + str(round(dur_recall, 4)))\n",
    "print(\"Duration F1: \" + str(round(dur_f1, 4)) + \"\\n\")\n",
    "\n",
    "micro_prec = (m_tp + dur_tp) / ((m_tp+dur_tp) + (m_fp+dur_fp))\n",
    "micro_rec = (m_tp + dur_tp) / ((m_tp+dur_tp) + (m_fn+dur_fn))\n",
    "micro_f1 = 2 * (micro_prec * micro_rec) / (micro_prec + micro_rec)\n",
    "\n",
    "print(\"Micro precision: \" + str(round(micro_prec, 4)))\n",
    "print(\"Micro recall: \" + str(round(micro_rec, 4)))\n",
    "print(\"Micro F1: \" + str(round(micro_f1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token matches, with Drools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug precision: 0.9448\n",
      "Drug recall: 0.818\n",
      "Drug F1: 0.8768\n",
      "\n",
      "Duration precision: 0.4706\n",
      "Duration recall: 0.2254\n",
      "Duration F1: 0.3048\n",
      "\n",
      "Micro precision: 0.92\n",
      "Micro recall: 0.7642\n",
      "Micro F1: 0.8349\n"
     ]
    }
   ],
   "source": [
    "m_tp = 0\n",
    "m_fn = 0\n",
    "m_fp = 0\n",
    "\n",
    "dur_tp = 0\n",
    "dur_fn = 0\n",
    "dur_fp = 0\n",
    "\n",
    "for filename in output_with_drools:\n",
    "    \n",
    "    pred_dict = {} # predicted medication index: related predicted duration index\n",
    "    gold_dict = {} # gold medication index: related gold duration index\n",
    "    \n",
    "    with open(\"./output_with_drools_i2b2/\"+filename) as m, open(\"./human_annotations/\"+filename) as h:\n",
    "        \n",
    "        machine_lines = m.readlines()\n",
    "        human_lines = h.readlines()\n",
    "        \n",
    "    for line in machine_lines:\n",
    "            \n",
    "        m = line.split('||')[0]\n",
    "        dur = line.split('||')[1]\n",
    "        m_idx = ' '.join(m.split()[-2:])\n",
    "            \n",
    "        if dur.lower().strip() == 'du=\"nm\"':\n",
    "            pred_dict[m_idx] = 'du=\"nm\"' \n",
    "        else:\n",
    "            dur_idx = ' '.join(dur.split()[-2:])\n",
    "            pred_dict[m_idx] = dur_idx\n",
    "                    \n",
    "    for line in human_lines:\n",
    "            \n",
    "        m = line.split('||')[0]\n",
    "        dur = line.split('||')[1]\n",
    "        m_idx = ' '.join(m.split()[-2:])\n",
    "            \n",
    "        if dur.lower().split() == 'du=\"nm\"':\n",
    "            gold_dict[m_idx] = 'du=\"nm\"'\n",
    "            \n",
    "        else:\n",
    "            dur_idx = ' '.join(dur.split()[-2:])\n",
    "            gold_dict[m_idx] = dur_idx\n",
    "                                \n",
    "    for drug, duration in pred_dict.items(): \n",
    "        pred_drug_line = int(drug.split(':')[0])\n",
    "        pred_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "        pred_drug_end_token = int(drug.split(':')[-1])\n",
    "        pred_drug = range(pred_drug_start_token, pred_drug_end_token+1)\n",
    "        drug_cnt = 0 # turns to 1 if a corresponding drug was found in the human annotations\n",
    "            \n",
    "        for drug in gold_dict.keys():\n",
    "            gold_drug_line = int(drug.split(':')[0])\n",
    "            try:\n",
    "                gold_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "            except: # one exception found were drug = \"217:1,217:3 217:3\" instead of \"217:1 217:3\"\n",
    "                gold_drug_start_token = int(drug.split(':')[1].split(',')[0])       \n",
    "            gold_drug_end_token = int(drug.split(':')[-1])\n",
    "            gold_drug = range(gold_drug_start_token, gold_drug_end_token+1)\n",
    "            overlap = set(pred_drug) & set(gold_drug)\n",
    "                \n",
    "            if pred_drug_line == gold_drug_line and overlap: \n",
    "                # corresponding drug mention found, assuming that drug mentions are not split over lines\n",
    "                \n",
    "                drug_cnt += 1\n",
    "                m_tp += len(overlap)\n",
    "                \n",
    "                if pred_drug_end_token > gold_drug_end_token:\n",
    "                    m_fp += pred_drug_end_token - gold_drug_end_token\n",
    "                if pred_drug_end_token < gold_drug_end_token:\n",
    "                    m_fn += gold_drug_end_token - pred_drug_end_token\n",
    "                if pred_drug_start_token < gold_drug_start_token:\n",
    "                    m_fp += gold_drug_start_token - pred_drug_start_token\n",
    "                if pred_drug_start_token > gold_drug_start_token:\n",
    "                    m_fn += pred_drug_start_token - gold_drug_start_token\n",
    "                    \n",
    "                break\n",
    "                    \n",
    "        if drug_cnt == 0:\n",
    "            m_fp += pred_drug_end_token - pred_drug_start_token + 1\n",
    "                \n",
    "        if duration.strip() != 'du=\"nm\"':\n",
    "            pred_start_line = int(duration.split(':')[0])\n",
    "            pred_end_line = int(duration.split(':')[1].split()[-1])\n",
    "            pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "            pred_dur_end_token = int(duration.split(':')[-1])\n",
    "            dur_cnt = 0 # turns to 1 if a corresponding duration was found in the human annotations\n",
    "            \n",
    "            if pred_start_line == pred_end_line:\n",
    "                pred_dur = range(pred_dur_start_token, pred_dur_end_token+1)\n",
    "                \n",
    "                for duration in gold_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        gold_dur_line = int(duration.split(':')[0])\n",
    "                        gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        gold_dur_end_token = int(duration.split(':')[-1])\n",
    "                        gold_dur = range(gold_dur_start_token, gold_dur_end_token+1)\n",
    "                        overlap = set(pred_dur) & set(gold_dur)\n",
    "                \n",
    "                        if pred_start_line == gold_dur_line and overlap:\n",
    "                            dur_cnt += 1\n",
    "                            dur_tp += len(overlap)\n",
    "                            \n",
    "                            if pred_dur_end_token > gold_dur_end_token:\n",
    "                                dur_fp += pred_dur_end_token - gold_dur_end_token\n",
    "                            if pred_dur_end_token < gold_dur_end_token:\n",
    "                                dur_fn += gold_dur_end_token - pred_dur_end_token\n",
    "                            if pred_dur_start_token < gold_dur_start_token:\n",
    "                                dur_fp += gold_dur_start_token - pred_dur_start_token\n",
    "                            if pred_dur_start_token > gold_dur_start_token:\n",
    "                                dur_fn += pred_dur_start_token - gold_dur_start_token\n",
    "                            break\n",
    "                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fp += pred_dur_end_token - pred_dur_start_token + 1\n",
    "                            \n",
    "            else:  \n",
    "                with open('./input/'+filename) as f:\n",
    "                    x = f.readlines()\n",
    "                    for idx, line in enumerate(x):\n",
    "                        if idx+1 == int(pred_start_line):\n",
    "                            line_len = len(line.split())\n",
    "                            break\n",
    "                            \n",
    "                for duration in gold_dict.values():\n",
    "                     if duration.strip() != 'du=\"nm\"':\n",
    "                        gold_start_line = int(duration.split(':')[0])\n",
    "                        gold_end_line = int(duration.split(':')[1].split()[-1])\n",
    "                        gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        gold_dur_end_token = int(duration.split(':')[-1])\n",
    "                                    \n",
    "                        if pred_start_line == gold_start_line and pred_end_line == gold_end_line:\n",
    "                            first_line_overlap = set(range(pred_dur_start_token, line_len)) & set(range(gold_dur_start_token, line_len))\n",
    "                            second_line_overlap = set(range(0, pred_dur_end_token+1)) & set(range(0, gold_dur_end_token+1))\n",
    "                            \n",
    "                            if first_line_overlap or second_line_overlap:\n",
    "                                dur_cnt += 1\n",
    "                                dur_tp += len(first_line_overlap)+len(second_line_overlap)\n",
    "                                \n",
    "                                if pred_dur_end_token > gold_dur_end_token:\n",
    "                                    dur_fp += pred_dur_end_token - gold_dur_end_token\n",
    "                                if pred_dur_end_token < gold_dur_end_token:\n",
    "                                    dur_fn += gold_dur_end_token - pred_dur_end_token\n",
    "                                if pred_dur_start_token < gold_dur_start_token:\n",
    "                                    dur_fp += gold_dur_start_token - pred_dur_start_token\n",
    "                                if pred_dur_start_token > gold_dur_start_token:\n",
    "                                    dur_fn += pred_dur_start_token - gold_dur_start_token\n",
    "                                break \n",
    "                        \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fp += (line_len - pred_dur_start_token) + (0 + pred_dur_end_token)\n",
    "                \n",
    "    for drug, duration in gold_dict.items():\n",
    "        \n",
    "        gold_drug_line = int(drug.split(':')[0])\n",
    "        try:\n",
    "            gold_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "        except:\n",
    "            gold_drug_start_token = int(drug.split(':')[1].split(',')[0])\n",
    "        gold_drug_end_token = int(drug.split(':')[-1])\n",
    "        gold_drug = range(gold_drug_start_token, gold_drug_end_token+1)\n",
    "        gold_cnt = 0\n",
    "            \n",
    "        for drug in pred_dict.keys():\n",
    "            \n",
    "            pred_drug_line = int(drug.split(':')[0])\n",
    "            pred_drug_start_token = int(drug.split(':')[1].split()[0])\n",
    "            pred_drug_end_token = int(drug.split(':')[-1])\n",
    "            pred_drug = range(pred_drug_start_token, pred_drug_end_token+1)\n",
    "            overlap = set(pred_drug) & set(gold_drug)\n",
    "                \n",
    "            if pred_drug_line == gold_drug_line and overlap:\n",
    "                drug_cnt += 1\n",
    "                break\n",
    "                \n",
    "        if drug_cnt == 0:\n",
    "            m_fn += len(gold_drug)\n",
    "            \n",
    "        if duration != 'du=\"nm\"':\n",
    "            gold_dur_start_line = int(duration.split(':')[0])\n",
    "            gold_dur_end_line = int(duration.split(':')[1].split()[-1])\n",
    "            gold_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "            gold_dur_end_token = int(duration.split(':')[-1])\n",
    "            dur_cnt = 0\n",
    "            \n",
    "            if gold_dur_start_line == gold_dur_end_line:\n",
    "                gold_dur = range(gold_dur_start_token, gold_dur_end_token)\n",
    "                for duration in pred_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        pred_dur_line = int(duration.split(':')[0])\n",
    "                        pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        pred_dur_end_token = int(duration.split(':')[-1])\n",
    "                        pred_dur = range(pred_dur_start_token, pred_dur_end_token)\n",
    "                        overlap = set(pred_dur) & set(gold_dur)\n",
    "                \n",
    "                        if pred_dur_line == gold_dur_start_line and overlap:\n",
    "                            dur_cnt += 1\n",
    "                            break\n",
    "                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fn += len(gold_dur) \n",
    "                    \n",
    "            else:\n",
    "                for duration in pred_dict.values():\n",
    "                    if duration.strip() != 'du=\"nm\"':\n",
    "                        pred_dur_start_line = int(duration.split(':')[0])\n",
    "                        pred_dur_end_line = int(duration.split(':')[1].split()[-1])\n",
    "                        pred_dur_start_token = int(duration.split(':')[1].split()[0])\n",
    "                        pred_dur_end_token = int(duration.split(':')[-1])\n",
    "                        \n",
    "                        with open('./input/'+filename) as f:\n",
    "                            x = f.readlines()\n",
    "                            for idx, line in enumerate(x):\n",
    "                                if idx+1 == int(pred_start_line):\n",
    "                                    line_len = len(line.split())\n",
    "                                    break\n",
    "                                    \n",
    "                        if pred_dur_start_line == gold_dur_start_line and pred_dur_end_line == gold_dur_end_line:\n",
    "                            first_line_overlap = set(range(pred_dur_start_token, line_len)) & set(range(gold_dur_start_token, line_len))\n",
    "                            last_line_overlap = set(range(0, pred_dur_end_token+1)) & set(range(0, gold_dur_end_token+1))\n",
    "                            \n",
    "                            if first_line_overlap or second_line_overlap:\n",
    "                                dur_cnt += 1\n",
    "                                break\n",
    "                                \n",
    "                if dur_cnt == 0:\n",
    "                    dur_fn += len(gold_dur)\n",
    "                                                                         \n",
    "m_precision = m_tp / (m_tp + m_fp)\n",
    "m_recall = m_tp / (m_tp + m_fn)\n",
    "m_f1 = 2 * (m_precision * m_recall) / (m_precision + m_recall)\n",
    "\n",
    "print(\"Drug precision: \" + str(round(m_precision, 4)))\n",
    "print(\"Drug recall: \" + str(round(m_recall, 4)))\n",
    "print(\"Drug F1: \" + str(round(m_f1, 4)) + \"\\n\")\n",
    "\n",
    "dur_precision = dur_tp / (dur_tp + dur_fp)\n",
    "dur_recall = dur_tp / (dur_tp + dur_fn)\n",
    "dur_f1 = 2 * (dur_precision * dur_recall) / (dur_precision + dur_recall)\n",
    "\n",
    "print(\"Duration precision: \" + str(round(dur_precision, 4)))\n",
    "print(\"Duration recall: \" + str(round(dur_recall, 4)))\n",
    "print(\"Duration F1: \" + str(round(dur_f1, 4)) + \"\\n\")\n",
    "\n",
    "micro_prec = (m_tp + dur_tp) / ((m_tp+dur_tp) + (m_fp+dur_fp))\n",
    "micro_rec = (m_tp + dur_tp) / ((m_tp+dur_tp) + (m_fn+dur_fn))\n",
    "micro_f1 = 2 * (micro_prec * micro_rec) / (micro_prec + micro_rec)\n",
    "\n",
    "print(\"Micro precision: \" + str(round(micro_prec, 4)))\n",
    "print(\"Micro recall: \" + str(round(micro_rec, 4)))\n",
    "print(\"Micro F1: \" + str(round(micro_f1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
